{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbc5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sahla\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\sahla\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "!pip3 install torch\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "!pip3 install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020011a4-45e3-4747-8a08-099c1b483491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?', 'Welcome to booking ticket moviee booking']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.', 'Have a good day', 'Have a great day', '']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'tickets', 'patterns': ['what type of tickets are available?', 'what are the ticket prices?', 'How many tickets are available?', 'How many gold tickets are available?', 'How many platinum tickets are available?', 'How many silver tickets are available?', 'How many gold seats are their?', 'How many silver seats are their?', 'How many platinum seats are their?', 'Is their a student discount available?', ''], 'responses': ['Which type of ticket you want', 'We have platinum,gold and silver seats', 'We have 1 gold ticket left', 'We have 2 gold tickets', 'We have 3 gold ticket', 'We have some gold tickets left', 'We have 1 platinum ticket left', 'We have 2 platinum ticket', 'We have 3 platinum ticket', 'We have some platinum tickets available', 'We have 1 silver ticket left', 'We have 2 silver ticket', 'We have 3 silver ticket', 'We have some silver tickets available', 'Hi there, what can I do for you?', 'The prices range from 20-50 pounds', 'Yes, student discount is available']}, {'tag': 'movie', 'patterns': ['What all languages movie are shown?', 'Which all movie are being shown', 'What time is the movie? ', 'Where is the movie screening?', 'Which screen will the movie be screening?', 'Till what time can we arrive?', 'Is food allowed inside?', 'Is their 3D screen ?', 'What time slots are available for movie Mission Impossible?', 'What time slots are available for movie K.G.F 2?', 'What time slots are available for movie Moonfall?', 'What time slots are available for movie The contractor?', 'What time slots are available for movie Ambulance?', 'What time slots are available for movie RRR?', 'What time slots are available for movie The Spiderman?'], 'response': ['The movies that are being shown are Mission Impossible, K.G.F 2, Moonfall, The contractor, Ambulance, RRR, The Spiderman ', 'The movie time is mentioned in the Ticket page.If you want further information I can let you know', 'The movie is going to be screened on screen 1 which is 2D ', 'The movie is going to be screened on screen 3 which is 2D ', 'The movie is going to be screened on screen 2 which is 2D ', 'The movie is going to be screened on screen 4 which is 3D ', 'Yes, there is 3D screen in the theatre', \"You can arrive by anytime but it would be best to come before the moovie starts so that you don't miss it\", 'No food is not allowed inside', 'You can buy food from inside the theatre', '']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?', 'what all payment options are there', 'The payment is not being accepted', 'Error is coming while paying'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
     ]
    }
   ],
   "source": [
    "with open('newIntents.json') as f:\n",
    "    data = json.load(f)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8d6f0a-2886-4bd1-92d7-95eec5ac549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc36a485-4aca-4431-b96a-637754a0fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the tokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "stemmer = PorterStemmer()\n",
    "#traversing through the loop\n",
    "for intent in data['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "    #taking out the patterns and the tokenizing\n",
    "        w = tokenizer.tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5bd6de-5f86-4bce-bc07-50597e7de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 patterns\n",
      "8 tags: ['delivery', 'funny', 'goodbye', 'greeting', 'movie', 'payments', 'thanks', 'tickets']\n",
      "96 unique stemmed words: [\"'s\", '2', '3d', 'a', 'accept', 'all', 'allow', 'ambul', 'anyon', 'are', 'arriv', 'avail', 'be', 'bye', 'can', 'card', 'cash', 'come', 'contractor', 'credit', 'day', 'deliveri', 'discount', 'do', 'doe', 'error', 'food', 'for', 'funni', 'get', 'gold', 'good', 'goodby', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'imposs', 'insid', 'is', 'joke', 'k.g.f', 'know', 'languag', 'later', 'long', 'lot', 'mani', 'mastercard', 'me', 'mission', 'moonfal', 'movi', 'my', 'not', 'of', 'onli', 'option', 'pay', 'payment', 'paypal', 'platinum', 'price', 'rrr', 'screen', 'seat', 'see', 'ship', 'shown', 'silver', 'slot', 'someth', 'spiderman', 'student', 'take', 'tell', 'thank', 'that', 'the', 'their', 'there', 'ticket', 'till', 'time', 'type', 'we', 'what', 'when', 'where', 'which', 'while', 'will', 'with', 'you']\n"
     ]
    }
   ],
   "source": [
    "ignore_syntax = [\"?\",\"/\",\".\",\"!\", \"@\", \"#\", \"$\"]\n",
    "all_words = [stemmer.stem(w) for w in all_words if w not in ignore_syntax]\n",
    "\n",
    "#to remove the duplicate values\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aff849-e9cc-43ac-96e3-b5e410c4d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_sentence, words):\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6efce88-622b-4dc3-bea4-dee3bfea3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b894ae1-3062-4cb9-837e-ec63e926a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 8\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec1878e-63df-400e-90de-3f12a611b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3f8139-7f7b-4684-9a9e-505b5adc90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.3624\n",
      "Epoch [200/1000], Loss: 0.0295\n",
      "Epoch [300/1000], Loss: 0.0025\n",
      "Epoch [400/1000], Loss: 0.0147\n",
      "Epoch [500/1000], Loss: 0.0012\n",
      "Epoch [600/1000], Loss: 0.0007\n",
      "Epoch [700/1000], Loss: 0.0027\n",
      "Epoch [800/1000], Loss: 0.0002\n",
      "Epoch [900/1000], Loss: 0.0006\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "final loss: 0.0000\n",
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')\n",
    "\n",
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb52d80-014c-4d47-9bea-6226b4c38979",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de99ab8-f25c-4961-91c6-a8b291072ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "Sam: Hi there, what can I do for you?\n",
      "Sam: Hi there, what can I do for you?\n",
      "Sam: We have 1 platinum ticket left\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: Have a great day\n",
      "Sam: Yes, student discount is available\n",
      "Sam: We have 1 gold ticket left\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: We have 2 platinum ticket\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: Hi there, what can I do for you?\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: We have 3 silver ticket\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have some platinum tickets available\n",
      "Sam: We have 2 platinum ticket\n",
      "Sam: We have 3 platinum ticket\n",
      "Sam: We have platinum,gold and silver seats\n",
      "Sam: We have 3 gold ticket\n",
      "Sam: We have 1 platinum ticket left\n",
      "Sam: We have some gold tickets left\n",
      "Sam: We have some gold tickets left\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have some gold tickets left\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have 1 gold ticket left\n",
      "Sam: We have 3 platinum ticket\n",
      "Sam: We have some gold tickets left\n",
      "Sam: We have some platinum tickets available\n",
      "Sam: Hi there, what can I do for you?\n",
      "Sam: We have 3 silver ticket\n",
      "Sam: We have some silver tickets available\n",
      "Sam: We have 1 platinum ticket left\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: We have platinum,gold and silver seats\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: We have 3 platinum ticket\n",
      "Sam: Which type of ticket you want\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: We have 1 gold ticket left\n",
      "Sam: We have platinum,gold and silver seats\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: Hi there, what can I do for you?\n",
      "Sam: We have platinum,gold and silver seats\n",
      "Sam: We have 2 silver ticket\n",
      "Sam: The prices range from 20-50 pounds\n",
      "Sam: We have 3 gold ticket\n",
      "Sam: We have 1 platinum ticket left\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: We have some gold tickets left\n",
      "Sam: We have 1 platinum ticket left\n",
      "Sam: We have some gold tickets left\n",
      "Sam: The prices range from 20-50 pounds\n",
      "Sam: We have 1 silver ticket left\n",
      "Sam: We have 3 silver ticket\n",
      "Sam: We have 2 gold tickets\n",
      "Sam: Yes, student discount is available\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1528/2962508515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# sentence = \"do you use credit cards?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"quit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahla\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahla\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "with open('newIntents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenizer.tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608f9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a50193da942bf77f0c1ba24b19bd8604e132919c178ad26ac8b7e94fefd61c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
